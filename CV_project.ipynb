{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1763999764332
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint= \"https://lab1mohamedosama.cognitiveservices.azure.com/\"\n",
        "key= \"DeHwAiaMnQAbjHrBaZSkWr7l5NCzRsu06C9m1nVYvYa6X3U9fIx0JQQJ99BKACF24PCXJ3w3AAAFACOG1xt9\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1763999767290
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/media/quickstarts/presentation.png\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1763999770342
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_url = f\"{endpoint}/vision/v3.2/analyze\"\n",
        "header = {\"Ocp-Apim-Subscription-Key\":key}\n",
        "parm = {\"visualFeatures\":\"ImageType,Description,Faces,Objects,tags\"}\n",
        "data = {\"url\":image_url}\n",
        "\n",
        "response = requests.post(analyze_url,headers=header,params=parm,json=data)\n",
        "res =response.json()\n",
        "res"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "{'imageType': {'clipArtType': 0, 'lineDrawingType': 0},\n 'tags': [{'name': 'text', 'confidence': 0.9966012239456177},\n  {'name': 'clothing', 'confidence': 0.9801060557365417},\n  {'name': 'person', 'confidence': 0.9596296548843384},\n  {'name': 'display device', 'confidence': 0.9490274786949158},\n  {'name': 'indoor', 'confidence': 0.947483241558075},\n  {'name': 'wall', 'confidence': 0.9395941495895386},\n  {'name': 'media', 'confidence': 0.9306115508079529},\n  {'name': 'television set', 'confidence': 0.9280922412872314},\n  {'name': 'led-backlit lcd display', 'confidence': 0.9254804849624634},\n  {'name': 'flat panel display', 'confidence': 0.9209464192390442},\n  {'name': 'furniture', 'confidence': 0.9132548570632935},\n  {'name': 'lcd tv', 'confidence': 0.895058274269104},\n  {'name': 'man', 'confidence': 0.8883916735649109},\n  {'name': 'television', 'confidence': 0.8766454458236694},\n  {'name': 'video', 'confidence': 0.8746980428695679},\n  {'name': 'multimedia', 'confidence': 0.8719364404678345},\n  {'name': 'output device', 'confidence': 0.8585700988769531},\n  {'name': 'computer monitor', 'confidence': 0.844162106513977},\n  {'name': 'table', 'confidence': 0.8429560661315918},\n  {'name': 'screen', 'confidence': 0.7113153338432312},\n  {'name': 'standing', 'confidence': 0.7051211595535278},\n  {'name': 'design', 'confidence': 0.40424615144729614}],\n 'description': {'tags': ['text',\n   'person',\n   'indoor',\n   'electronics',\n   'television',\n   'standing',\n   'display'],\n  'captions': [{'text': 'a man pointing at a screen',\n    'confidence': 0.5098631381988525}]},\n 'faces': [],\n 'objects': [{'rectangle': {'x': 655, 'y': 83, 'w': 263, 'h': 605},\n   'object': 'person',\n   'confidence': 0.905},\n  {'rectangle': {'x': 75, 'y': 76, 'w': 678, 'h': 414},\n   'object': 'television',\n   'confidence': 0.808,\n   'parent': {'object': 'display', 'confidence': 0.851}}],\n 'requestId': '3c213eff-dd0e-4860-bae0-7699709f9e08',\n 'metadata': {'height': 692, 'width': 1038, 'format': 'Png'},\n 'modelVersion': '2021-05-01'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1763999773691
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_image(image_url):\n",
        "    \"\"\"Analyze image and extract caption + tags\"\"\"    \n",
        "    analyze_url = f\"{endpoint}/vision/v3.2/analyze\"\n",
        "    headers = {\"Ocp-Apim-Subscription-Key\": key}\n",
        "    params = {\"visualFeatures\": \"Description,Tags\"}\n",
        "    data = {\"url\": image_url}\n",
        "    \n",
        "    response = requests.post(analyze_url, headers=headers, params=params, json=data)\n",
        "    result = response.json()\n",
        "    \n",
        "    # Extract caption\n",
        "    caption = \"\"\n",
        "    if 'description' in result:\n",
        "        captions = result['description'].get(\"captions\", [])\n",
        "        if captions:\n",
        "            caption = captions[0]['text']\n",
        "    \n",
        "    # Extract tags\n",
        "    tags = []\n",
        "    if 'tags' in result:\n",
        "        tags = [tag['name'] for tag in result['tags']]\n",
        "    \n",
        "    # Create vision context summary\n",
        "    vision_context = f\"Image description: {caption}\\nImage tags: {', '.join(tags)}\"\n",
        "    \n",
        "    return vision_context, caption, tags, result"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1764000221515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vision_context, caption, tags, result = analyze_image(image_url)\n",
        "print(vision_context)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Image description: a man pointing at a screen\nImage tags: text, clothing, person, display device, indoor, wall, media, television set, led-backlit lcd display, flat panel display, furniture, lcd tv, man, television, video, multimedia, output device, computer monitor, table, screen, standing, design\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1764000225769
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.generativeai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[1;32m      2\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mAIzaSyBWcTBjqIyHtLSriSke6wvw20GeVIZfSRY)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.generativeai'"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1764000309101
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting google-generativeai\n  Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m453.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: google-auth>=2.15.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-generativeai) (2.38.0)\nCollecting google-api-python-client\n  Downloading google_api_python_client-2.187.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-generativeai) (4.14.1)\nRequirement already satisfied: google-api-core in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-generativeai) (2.24.2)\nCollecting google-ai-generativelanguage==0.6.15\n  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-generativeai) (4.25.8)\nRequirement already satisfied: pydantic in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-generativeai) (2.9.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.69.2)\nRequirement already satisfied: requests<3.0.0,>=2.18.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.4)\nCollecting httplib2<1.0.0,>=0.19.0\n  Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting google-auth-httplib2<1.0.0,>=0.2.0\n  Downloading google_auth_httplib2-0.2.1-py3-none-any.whl (9.5 kB)\nCollecting uritemplate<5,>=3.0.1\n  Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\nRequirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.23.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.71.0)\nCollecting grpcio-status<2.0.dev0,>=1.33.2\n  Downloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\nRequirement already satisfied: pyparsing<4,>=3.0.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.9)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n  Downloading grpcio_status-1.75.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.75.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.74.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.73.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.73.0-py3-none-any.whl (14 kB)\nCollecting grpcio<2.0dev,>=1.33.2\n  Downloading grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting grpcio-status<2.0.dev0,>=1.33.2\n  Downloading grpcio_status-1.72.2-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.72.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\nCollecting protobuf\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: uritemplate, protobuf, httplib2, grpcio, grpcio-status, google-auth-httplib2, google-api-python-client, google-ai-generativelanguage, google-generativeai\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.25.8\n    Uninstalling protobuf-4.25.8:\n      Successfully uninstalled protobuf-4.25.8\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.71.0\n    Uninstalling grpcio-1.71.0:\n      Successfully uninstalled grpcio-1.71.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\nmlflow-skinny 2.21.3 requires packaging<25, but you have packaging 25.0 which is incompatible.\nazureml-training-tabular 1.60.0 requires scipy<1.11.0,>=1.0.0, but you have scipy 1.11.0 which is incompatible.\nazureml-training-tabular 1.60.0 requires urllib3<2.0.0, but you have urllib3 2.5.0 which is incompatible.\nazureml-train-automl-runtime 1.60.0 requires urllib3<2.0.0, but you have urllib3 2.5.0 which is incompatible.\nazureml-mlflow 1.60.0 requires azure-storage-blob<=12.19.0,>=12.5.0, but you have azure-storage-blob 12.25.1 which is incompatible.\nazureml-automl-runtime 1.60.0 requires urllib3<2.0.0, but you have urllib3 2.5.0 which is incompatible.\nazureml-automl-dnn-nlp 1.60.0 requires torch==2.2.2, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15 google-api-python-client-2.187.0 google-auth-httplib2-0.2.1 google-generativeai-0.8.5 grpcio-1.76.0 grpcio-status-1.71.2 httplib2-0.31.0 protobuf-5.29.5 uritemplate-4.2.0\n"
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyBPucQmtN3_o1crt06oDLzgRlgkkxQEhCg\")"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1764000676341
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "response = model.generate_content(\"Say 'Hello World'\")\n",
        "print(response.text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Hello World!\n\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1764000679850
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK 2: Creative Text Generation\n",
        "def generate_creative_content(vision_context):\n",
        "    prompt = f\"\"\"\n",
        "Using this image analysis:\n",
        "\n",
        "{vision_context}\n",
        "\n",
        "Write a short paragraph (3–4 sentences) describing the scene in a simple and creative way.\n",
        "\"\"\"\n",
        "    return model.generate_content(prompt).text  "
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1764000843753
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=generate_creative_content(vision_context)\n",
        "print(text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "In a brightly lit room, a man stands, his attention focused on a glowing screen. He gestures towards the display, perhaps explaining a complex chart or highlighting a key piece of information. The screen's light illuminates his face, casting a soft glow on the surrounding furniture as he commands the presentation.\n\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1764000846870
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rewrite_in_style(original_text, target_style):\n",
        "    \"\"\"\n",
        "    Rewrites a given paragraph in a new writing style using Gemini.\n",
        "    \n",
        "    target_style examples:\n",
        "        - \"Arabic poetic style\"\n",
        "        - \"Marketing advertising style\"\n",
        "        - \"Child-friendly storytelling style\"\n",
        "        - \"Professional academic style\"\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a rewriting assistant. \n",
        "Rewrite the following paragraph in the style of: {target_style}\n",
        "\n",
        "Original paragraph:\n",
        "{original_text}\n",
        "\n",
        "Rewrite it clearly, keeping the meaning but fully changing the tone and style.\n",
        "\"\"\"\n",
        "    return model.generate_content(prompt).text "
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1764001408034
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_for_children=rewrite_in_style(vision_context,\"professional academic style\")\n",
        "print(text_for_children)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The image depicts a male individual gesturing towards a digital display. The setting appears to be an interior space, characterized by the presence of a wall and various furnishings. The display itself is identifiable as a flat-panel LCD television, exhibiting characteristics of LED backlighting technology. Additional elements present in the visual composition include textual information on the screen, articles of clothing worn by the individual, and auxiliary technological components. The subject is standing, potentially in a presentation or demonstrative context, interacting with the multimedia output.\n\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1764001411595
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, uuid, json\n",
        "\n",
        "def translate_text(text, to_languages):\n",
        "    \"\"\"\n",
        "    Translate a given text to one or more target languages using Azure Translator.\n",
        "    \n",
        "    Parameters:\n",
        "    - text (str): The text to translate.\n",
        "    - to_languages (list): List of language codes, e.g., ['ar', 'zu'].\n",
        "    - key (str): Azure Translator subscription key.\n",
        "    - endpoint (str): Azure Translator endpoint URL.\n",
        "    - location (str): Azure region, e.g., 'uaenorth'.\n",
        "    \n",
        "    Returns:\n",
        "    - dict: Translations with language codes as keys.\n",
        "    \"\"\"\n",
        "    path = '/translate'\n",
        "    endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
        "    constructed_url = endpoint + path\n",
        "\n",
        "    params = {\n",
        "        'api-version': '3.0',\n",
        "        'from': 'en',\n",
        "        'to': to_languages\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        'Ocp-Apim-Subscription-Key': \"BcCzXIVw5H2pYxniWIhMuV4BYqjqJaZrfYoTRMcPJSyRerEvZP4lJQQJ99BKACF24PCXJ3w3AAAbACOGsVC0\",\n",
        "        'Ocp-Apim-Subscription-Region': \"uaenorth\",\n",
        "        'Content-type': 'application/json',\n",
        "        'X-ClientTraceId': str(uuid.uuid4())\n",
        "    }\n",
        "\n",
        "    body = [{'text': text}]\n",
        "\n",
        "    request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
        "    response = request.json()\n",
        "\n",
        "    # Format output as {language: translated_text}\n",
        "    translations = {}\n",
        "    for item in response:\n",
        "        for t in item.get('translations', []):\n",
        "            translations[t['to']] = t['text']\n",
        "\n",
        "    return translations\n"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1764001682151
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trans=translate_text(text,\"ar\")\n",
        "print(trans)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'ar': 'في غرفة مضاءة بشكل ساطع، يقف رجل، وتركيزه على شاشة متوهجة. يشير نحو العرض، ربما يشرح مخططا معقدا أو يبرز معلومة رئيسية. يضيء ضوء الشاشة وجهه، ملقيا وهجا ناعما على الأثاث المحيط بينما يسيطر على العرض.\\n'}\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1764001702588
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}